# NIST AI Risk Management Framework (AI RMF) Checklist

**Purpose**: Voluntary framework to manage AI risks – Govern, Map, Measure, Manage.  
**Source**: NIST AI RMF 1.0 (2023) + Generative AI Profile (2024)  
**License**: MIT – Free to use

## Govern (Organizational culture & policies)
- [ ] Appoint AI risk management lead/roles
- [ ] Establish AI risk tolerance & policies
- [ ] Document legal/regulatory requirements (e.g., EU AI Act alignment)
- [ ] Ensure workforce AI literacy & training

## Map (Context & risk framing)
- [ ] Identify AI system scope & stakeholders
- [ ] Document intended use cases & impacts
- [ ] Identify foreseeable benefits & harms
- [ ] Map to external standards (EU AI Act, OWASP LLM)

## Measure (Assess & track risks)
- [ ] Define & collect metrics (accuracy, bias, fairness, robustness)
- [ ] Conduct testing (red-teaming, adversarial, bias audits)
- [ ] Track emergent risks post-deployment
- [ ] Use quantitative/qualitative assessments

## Manage (Prioritize & act on risks)
- [ ] Prioritize risks based on impact/likelihood
- [ ] Implement controls & mitigations
- [ ] Establish incident response for AI harms
- [ ] Continuously monitor & improve

**Generative AI Specific (from NIST Profile)**:
- [ ] Evaluate for prompt injection & output leakage
- [ ] Assess training data risks & model provenance
- [ ] Implement content labeling/watermarking

**Integration Tip**: Use this alongside EU AI Act & OWASP checklists.  
Automate parts at https://aiaudittool.net.

**References**:
- Official NIST AI RMF: https://www.nist.gov/itl/ai-risk-management-framework
- Playbook: https://airc.nist.gov/airmf-resources/playbook