# EU AI Act Compliance Checklist (2026 Ready)

**Purpose**: Self-assessment tool to classify AI systems, identify obligations, and prepare for full enforcement (most rules apply from August 2026).  
**Version**: 1.0 – January 2026  
**Author**: Aiaudittool.net 
**License**: MIT – Free to use/modify

## Step 1: Is it an AI System? (Article 3)
- [ ] Does the system use machine learning, logic-based, statistical, or knowledge-based approaches?  
- [ ] Is it designed to generate outputs (predictions, recommendations, decisions) influencing environments?  
→ If **No** to either → Not in scope.  
→ If **Yes** → Proceed.

## Step 2: Risk Classification
- [ ] **Unacceptable Risk** (Prohibited – Annex I, effective Feb 2026)  
  - Social scoring  
    - Real-time remote biometric ID in public (exceptions apply)  
      - Emotion recognition in workplaces/education  
        → If yes → Ban deployment immediately.

        - [ ] **High-Risk** (Annex III – strict obligations)  
          - Biometrics, critical infrastructure, education/vocational training, employment, law enforcement, migration, justice  
            → If yes → Full requirements below.

            - [ ] **Limited Risk** (Transparency only)  
              - Chatbots, deepfakes, emotion recognition, generative AI content  
                → Disclose AI interaction.

                - [ ] **Minimal Risk**  
                  → No obligations – voluntary codes encouraged.

                  ## Step 3: High-Risk Obligations Checklist (if applicable)
                  ### General
                  - [ ] Conduct Fundamental Rights Impact Assessment (FRIA) where required
                  - [ ] Register system in EU database (post-conformity)

                  ### Providers (Developers)
                  - [ ] Implement risk management system (continuous)
                  - [ ] Use high-quality training datasets (bias mitigation)
                  - [ ] Ensure technical documentation & record-keeping (10 years)
                  - [ ] Automatic logging for traceability
                  - [ ] Provide instructions for deployers
                  - [ ] Achieve CE marking & EU declaration of conformity
                  - [ ] Post-market monitoring plan

                  ### Deployers (Users)
                  - [ ] Human oversight & monitoring
                  - [ ] Inform natural persons of AI interaction
                  - [ ] Ensure input data relevance/accuracy
                  - [ ] Monitor operation & report serious incidents

                  ### Transparency (All Limited/High-Risk Generative AI)
                  - [ ] Label AI-generated content (e.g., watermarks for images/audio/video)
                  - [ ] Publish summaries of training data (copyright compliance)

                  **Next Steps**:
                  - Document everything → Use https://aiaudittool.net for automated mapping & verification.
                  - Review annually or after system changes.

                  **References**:
                  - Official Text: https://artificialintelligenceact.eu
                  - Compliance Checker: https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker